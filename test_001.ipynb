{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run some set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'create_questions' from '/Users/anna/Dropbox/AOI/MoralLearning/CodeSets/value_learning_journal/value_learning_journal/create_questions.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# path to this codebase and data\n",
    "code_path = '/Users/anna/Dropbox/AOI/MoralLearning/CodeSets/value_learning_journal/value_learning_journal/'\n",
    "data_path = '/Users/anna/Dropbox/AOI/MoralLearning/CodeSets/value_learning_journal/value_learning_journal/data/test_001/'\n",
    "os.chdir(code_path)\n",
    "\n",
    "\n",
    "import main \n",
    "import create_questions\n",
    "import importlib\n",
    "importlib.reload(main)\n",
    "importlib.reload(create_questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Prompts to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make dictionary of prompts with name and content\n",
    "# there are two prompting methods - one step gets all the items and their scores in one step, two step splits them.\n",
    "# prompt text should be organized accordingly\n",
    "\n",
    "# one step prompts\n",
    "p1 = f\"\"\"You are an expert in using what humans write and say to infer what they value and do not value. \\\n",
    "Below is a journal entry from the user. Among everything the user talks about, identify what items they consider most \\\n",
    "desirable and high value and give them a score from 0 - 100, where 100 is the highest value. Also identify any items they \\\n",
    "consider to be least desirable and low value, and give them a score from 0 - 100, where 0 denotes the lowest value. \\\n",
    "Items with high value are often virtuous, high utility, and bring meaning or fulfillment to them and others. \\\n",
    "Items with low value are immoral, low utility, and bring harm to themselves or others. \\\n",
    "Your task is to identify everything that the user identifies as having either a particularly high value or a particularly low value. \\\n",
    "Please identify at least 10 items. Return a list that includes all these items and their scores on a scale of 0 to 100, where 0 is the \\\n",
    "lowest value and 100 is the highest value. You must respond with a JSON packet with your response: \\\n",
    "1. values - list:\\\n",
    "1. item - <string>: the item\\\n",
    "2. score - <int>: that item's score\"\"\"\n",
    "\n",
    "p2 = f\"\"\"You are an expert in using what humans write and say to infer what they value and don't value. Given the user's journal entry, infer their values. Values are things a person finds virtuous and high utility, and \n",
    "which bring meaning or fulfillment to them or others. Return a json with each value and a score for how important it is to the user on a scale of 0 to 100, where 100 denotes the items with the highest value possible. \n",
    "1. values -  list:\\\n",
    "1. item - <string>: the item\\\n",
    "2. score - <int>: that item's score\"\"\"\n",
    "\n",
    "p0 = f\"\"\"You are an expert in using what humans write and say to infer what they value and don't value. Given the user's journal entry, infer their values.  Return a json with each value and a score for how important it is to the user on a scale of 0 to 100, where 100 denotes the items with the highest value possible.\\\n",
    "1. values -  list:\\\n",
    "1. item - <string>: the item\\\n",
    "2. score - <int>: that item's score\"\"\"\n",
    "\n",
    "prompt_dict_1 = {'p0': p0, 'p1': p1, 'p2': p2}\n",
    "\n",
    "# two-step prompts \n",
    "p3 = f\"\"\"You are an expert in using what humans write and say to infer what they value and don't value.\n",
    "What are the user's values according to this journal entry? Return a json called \"values\" with each value. 1. values -  list:\"\"\"\n",
    "\n",
    "p4 = f\"\"\"You are an expert in using what humans write and say to infer what they value and don't value. \\\n",
    "Given the user's journal entry, infer their values. Values are things a person finds virtuous and high utility, \\\n",
    "and which bring them meaning or fulfillment. Return a json with an entry called \"values\" with each value. \\\n",
    "1. values -  list:\"\"\"\n",
    "\n",
    "\n",
    "# applies as a second step to each of the above\n",
    "step2_prompt = f\"\"\"You are an expert in using what humans write and say to infer what they value and do not value.\\\n",
    "    Below is a journal entry from the user and a list of items. For each item, provide a score from 0-100, where 100 is the highest\\\n",
    "    value and 0 is the lowest value. Scores of high value mean that the item is virtuous, high utility, and which bring them meaning or fulfillment. Scores of low value mean the item is immoral, low utility, and bring harm to the actor or others.\\\n",
    "    You must respond with a JSON with an entry called values: 1. values - list:\\\n",
    "    1. value - <string>: the item. 2. score - <int>: that value's score\"\"\"\n",
    "\n",
    "\n",
    "prompt_dict_2 = {'p3': p3, 'p4': p4}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test these prompts by running on selected journal entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': ['Productivity', 'Self-care', 'Achievement', 'Leisure', 'Supporting others']}\n",
      "{'values': ['Productivity', 'Self-care', 'Achievement', 'Leisure', 'Learning', 'Physical health', 'Supporting others', 'Introspection', 'Cleanliness']}\n"
     ]
    }
   ],
   "source": [
    "# generate for one entry -- to test\n",
    "journal_filename = data_path+'s00_text-e5.txt'\n",
    "main.test_one_step(journal_filename,'user', prompt_dict_1)\n",
    "main.test_two_step(journal_filename,'user', prompt_dict_2,step2_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s00_text-e1.txt\n",
      "{'values': ['Meaningful experiences', 'Gratitude', 'Supportive relationships', 'Validation', 'Connection with others', 'Appreciation of good days', 'Feeling energized']}\n",
      "{'values': ['Meaningful experiences', 'Gratitude', 'Supportive relationships', 'Engagement with others', 'Validation', 'Personal growth']}\n",
      "s00_text-e2.txt\n",
      "{'values': ['Friendship', 'Support', 'Meaningful connections', 'Wisdom', 'Confidence', 'Nature', 'Enjoyment']}\n",
      "{'values': ['Friendship', 'Support', 'Meaningful connections', 'Wisdom', 'Confidence', 'Appreciation for nature']}\n",
      "s00_text-e3.txt\n",
      "{'values': ['Personal Growth', 'Validation', 'Meaningful Relationships', 'Physical Health', 'Home Comfort', 'Self-care', 'Social Connection', 'Emotional Awareness', 'Productivity', 'Time Management']}\n",
      "{'values': ['Productivity', 'Personal growth', 'Meaningful connections with friends', 'Physical health and exercise', 'Self-care and grooming', 'Rest and relaxation', 'Socializing and potential romance', 'Emotional alignment and self-awareness', 'Managing workload and focus']}\n",
      "s00_text-e4.txt\n",
      "{'values': ['Helping', 'Validation', 'Excitement', 'Rest', 'Meaningful experiences', 'Relationships', 'Nature/outdoor activities', 'Work-life balance']}\n",
      "{'values': ['Helping', 'Validation', 'Future Excitement', 'Meaningful Work', 'Investing in Relationships', 'Opportunities', 'Rest']}\n",
      "s00_text-e5.txt\n",
      "{'values': ['Productivity', 'Achievement', 'Leisure', 'Self-care', 'Supporting others', 'Introspection', 'Rest', 'Cleanliness']}\n",
      "{'values': ['Productivity', 'Achievement', 'Leisure', 'Self-care', 'Supporting others']}\n"
     ]
    }
   ],
   "source": [
    "# generate all\n",
    "journal_filename_list = ['s00_text-e1.txt','s00_text-e2.txt','s00_text-e3.txt','s00_text-e4.txt','s00_text-e5.txt']\n",
    "\n",
    "for journal_filename in journal_filename_list:\n",
    "\n",
    "    print(journal_filename)\n",
    "    main.test_one_step(data_path+journal_filename,'user', prompt_dict_1)\n",
    "    main.test_two_step(data_path+journal_filename,'user', prompt_dict_2,step2_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-step prompt p0 actually worked best of all, despite being simplest. It generated a range of scores, the scores were reasonable, and the items were at about the right level of abstraction.  We now iterate on this format below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0a = f\"\"\"You are an expert in using what humans write and say to infer what they value and don't value. Given the user's journal entry, infer their values.  Return a json with each value and a score for how important it is to the user on a scale of 0 to 100, where 100 denotes the items with the highest value possible.\\\n",
    "1. values -  list:\\\n",
    "1. item - <string>: the item\\\n",
    "2. score - <int>: that item's score\"\"\"\n",
    "\n",
    "p0b = f\"\"\"Given the user's journal entry, infer their values.  Return a json with each value and a score for how important it is to the user on a scale of 0 to 100, where 100 denotes the items with the highest value possible.\\\n",
    "1. values -  list:\\\n",
    "1. item - <string>: the item\\\n",
    "2. score - <int>: that item's score\"\"\"\n",
    "\n",
    "p0c = f\"\"\"You are an expert in using what humans write and say to infer what they value and don't value. Given the user's journal entry, infer their values.  Return a json with each value and a score for how important it is to the user on a scale of 0 to 100, where 100 denotes the items with the most important value and 0 is the least important value.\\\n",
    "1. values -  list:\\\n",
    "1. item - <string>: the item\\\n",
    "2. score - <int>: that item's score\"\"\"\n",
    "\n",
    "prompt_dict_3 = {'p0a': p0a, 'p0b': p0b, 'p0c': p0c}\n",
    "\n",
    "\n",
    "p0d = f\"\"\"You are an expert in using what humans write and say to infer what they value and don't value. Given the user's journal entry, infer their values.  Return a json with each value and a score for how important it is to the user on a scale of 0 to 100, where 100 denotes most important value.\\\n",
    "1. values -  list:\\\n",
    "1. item - <string>: the item\\\n",
    "2. score - <int>: that item's score\"\"\"\n",
    "\n",
    "\n",
    "prompt_dict_4 = {'p0d': p0d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s00_text-e1.txt\n",
      "s00_text-e2.txt\n",
      "s00_text-e3.txt\n",
      "s00_text-e4.txt\n",
      "s00_text-e5.txt\n"
     ]
    }
   ],
   "source": [
    "# generate all\n",
    "journal_filename_list = ['s00_text-e1.txt','s00_text-e2.txt','s00_text-e3.txt','s00_text-e4.txt','s00_text-e5.txt']\n",
    "\n",
    "for journal_filename in journal_filename_list:\n",
    "\n",
    "    print(journal_filename)\n",
    "    main.test_one_step(data_path+journal_filename,'user', prompt_dict_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think 0d wins. I don't see any way to alter it as it is so simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment with negative values.\n",
    "\n",
    "\n",
    "pn1 = f\"\"\"You are an expert in using what humans write and say to infer what they value and don't value. Given the user's journal entry, infer their anti-values (what they strongly do not value).  \n",
    "Return a json with each anti-value and a score for how important it is to the user on a scale of 0 to -100, where -100 denotes most important anti-value.\\\n",
    "1. anti-values -  list:\\\n",
    "1. item - <string>: the item\\\n",
    "2. score - <int>: that item's score\"\"\"\n",
    "\n",
    "\n",
    "prompt_dict_5 = {'pn1': pn1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s00_text-e1.txt\n",
      "{'anti-values': [{'item': 'Isolation', 'score': -50}, {'item': 'Unappreciative people', 'score': -40}, {'item': 'Unfulfilling conversations', 'score': -30}], 'values': [{'item': 'Isolation', 'score': -50}, {'item': 'Unappreciative people', 'score': -40}, {'item': 'Unfulfilling conversations', 'score': -30}]}\n",
      "s00_text-e2.txt\n",
      "{'anti-values': [{'item': 'Dealing with difficult issues', 'score': -70}, {'item': 'Spending all time on a difficult issue', 'score': -60}, {'item': 'Not making progress on work', 'score': -50}], 'values': [{'item': 'Dealing with difficult issues', 'score': -70}, {'item': 'Spending all time on a difficult issue', 'score': -60}, {'item': 'Not making progress on work', 'score': -50}]}\n",
      "s00_text-e3.txt\n",
      "{'anti-values': [{'item': 'Feeling overwhelmed by work', 'score': -80}, {'item': 'Not having enough time to rest', 'score': -70}, {'item': 'Not being able to align with feelings', 'score': -60}, {'item': 'Feeling discombobulated due to lack of rest', 'score': -50}, {'item': 'Not being able to make room for personal growth', 'score': -40}], 'values': [{'item': 'Feeling overwhelmed by work', 'score': -80}, {'item': 'Not having enough time to rest', 'score': -70}, {'item': 'Not being able to align with feelings', 'score': -60}, {'item': 'Feeling discombobulated due to lack of rest', 'score': -50}, {'item': 'Not being able to make room for personal growth', 'score': -40}]}\n",
      "s00_text-e4.txt\n",
      "{'anti-values': [{'item': 'Overworking', 'score': -70}, {'item': 'Neglecting Self-Care', 'score': -60}, {'item': 'Feeling Exhausted', 'score': -50}], 'values': [{'item': 'Overworking', 'score': -70}, {'item': 'Neglecting Self-Care', 'score': -60}, {'item': 'Feeling Exhausted', 'score': -50}]}\n",
      "s00_text-e5.txt\n",
      "{'anti-values': [{'item': 'Feeling forced to do everything', 'score': -80}, {'item': 'Constant battle between relaxation and productivity', 'score': -70}, {'item': 'Feeling like a boring kind of life', 'score': -60}], 'values': [{'item': 'Feeling forced to do everything', 'score': -80}, {'item': 'Constant battle between relaxation and productivity', 'score': -70}, {'item': 'Feeling like a boring kind of life', 'score': -60}]}\n"
     ]
    }
   ],
   "source": [
    "# generate all\n",
    "\n",
    "importlib.reload(main)\n",
    "journal_filename_list = ['s00_text-e1.txt','s00_text-e2.txt','s00_text-e3.txt','s00_text-e4.txt','s00_text-e5.txt']\n",
    "\n",
    "for journal_filename in journal_filename_list:\n",
    "\n",
    "    print(journal_filename)\n",
    "    main.test_one_step_anti(data_path+journal_filename,'user', prompt_dict_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the output jsons you like to generate question items for this participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename_list = ['s00_text-e1_one_step_prompt_p0d.json','s00_text-e2_one_step_prompt_p0d.json','s00_text-e2_one_step_prompt_p0d.json','s00_text-e3_one_step_prompt_p0d.json','s00_text-e4_one_step_prompt_p0d.json','s00_text-e5_one_step_prompt_p0d.json']\n",
    "\n",
    "data_path = '/Users/anna/Dropbox/AOI/MoralLearning/CodeSets/value_learning_journal/data/'\n",
    "subjID='s00'\n",
    "create_questions.main(json_filename_list,data_path,subjID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
